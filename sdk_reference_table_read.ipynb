{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2931f0b8-932e-4495-bcfc-b155f7926f8c",
   "metadata": {},
   "source": [
    "# SDK Reference Table - `table()` - read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa337205-736f-4da7-a3ba-4e512aae845b",
   "metadata": {},
   "source": [
    "Ocean Data Platform offers both API and Python SDK interfaces. This notebook highlights the Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefd9e9-e012-4e14-9c45-07074806d1e5",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb2251-8483-4d41-995b-0037bd6d2598",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install -U odp-sdk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23ef82-6ba5-4e2e-a88a-2997b7b64a11",
   "metadata": {},
   "source": [
    "## Client Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c34a6c-aa35-4588-8dd3-b9e57cfe277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odp.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e70b5f5-c062-4793-bcc6-823b51f3fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2397c384-abb3-4af8-b9cc-a7b43b8aeaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto authentication which opens browser to performance authentication process (not in our Workspaces)\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537b5f9c-6af6-49f1-b354-f17a0c1b1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key authentication (don't need to open browser).\n",
    "# You can generate an API key in the Ocean Data Platform web interface, under your user profile.\n",
    "client = Client(api_key=\"your-api-key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c338c-08f9-46f2-8270-a79e0e6787e4",
   "metadata": {},
   "source": [
    "## Dataset Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436a77e-ce7b-4446-9603-154430148dbf",
   "metadata": {},
   "source": [
    "With an initialized `Client` you can access different datasets by using the datasets' UUID. The easiest way is to use https://app.hubocean.earth/catalog to search for datasets and find the UUID (click API).\n",
    "\n",
    "For the Table examples we are using a dataset from Brazil provided from one of our partners: \n",
    "\n",
    "**Example Dataset**: PGS Biota Data - Mammal and Turtle Observations (Darwin Core Format)  \n",
    "**Dataset ID**: `1d801817-742b-4867-82cf-5597673524eb`  \n",
    "**Columns**:`occurrenceID`,`verbatimIdentification`,`scientificName`,`scientificNameID`,`lifeStage`,`individualCount`,`basisOfRecord`,`minimumDepthInMeters`,`eventDate`,`occurrenceRemarks`,`decimalLongitude`,`decimalLatitude`,`footprintWKT`,`license`,`occurrenceStatus`,`geodeticDatum`,`datasetName`,`institutionCode`,`otherCatalogNumbers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afa098-23b8-47a5-9adb-161d8a4d9cbc",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566ec9c9-3ffb-4ba4-9bd4-dacec00c72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = client.dataset(\"1d801817-742b-4867-82cf-5597673524eb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e693c-5241-4467-8bf0-64b457586ae2",
   "metadata": {},
   "source": [
    "The `dataset` from this UUID will be used in the examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0a548-de9a-4649-9d1e-ed9d509e4076",
   "metadata": {},
   "source": [
    "## Get Dataset Schema and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8531c587-fa4a-4c19-943b-70bbc799f2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: occurrenceID: string\n",
      "verbatimIdentification: string\n",
      "scientificName: string\n",
      "scientificNameID: string\n",
      "lifeStage: string\n",
      "individualCount: double\n",
      "basisOfRecord: string\n",
      "minimumDepthInMeters: double\n",
      "eventDate: string\n",
      "occurrenceRemarks: string\n",
      "decimalLongitude: double\n",
      "decimalLatitude: double\n",
      "footprintWKT: string\n",
      "  -- field metadata --\n",
      "  isGeometry: '1'\n",
      "  class: 'geometry'\n",
      "  index: '1'\n",
      "license: string\n",
      "occurrenceStatus: string\n",
      "geodeticDatum: string\n",
      "datasetName: string\n",
      "institutionCode: string\n",
      "otherCatalogNumbers: string\n"
     ]
    }
   ],
   "source": [
    "# Get table schema\n",
    "schema = dataset.table.schema()  # Returns pyarrow.Schema or None\n",
    "print(f\"Available columns: {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfad0cd-493f-4d2a-9816-f86477130870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 2,241\n",
      "Dataset size: 350,374 bytes\n"
     ]
    }
   ],
   "source": [
    "# Get table statistics  \n",
    "stats = dataset.table.stats()\n",
    "print(f\"Total observations: {stats.num_rows:,}\")  \n",
    "print(f\"Dataset size: {stats.size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93cf95-a262-4ca7-a746-02eaa7920824",
   "metadata": {},
   "source": [
    "## Query Table Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f79e0-fd1b-465a-b3db-17d650936da5",
   "metadata": {},
   "source": [
    "You query the Table data by using `table.select()` followed by how you want to receive the results.\n",
    "\n",
    "There are three different ways of receiving the results from the query:\n",
    "\n",
    "Single batch\n",
    "- A GeoPandas GeoDataFrame containing all the data (for smaller datasets or a quick view of the data): `dataset.table.select().all().dataframe()`\n",
    "\n",
    "Streaming batches\n",
    "- A stream of GeoPandas GeoDataFrames (if the dataset is too large): `dataset.table.select().dataframes()`\n",
    "- A stream of PyArrow RecordBatches (a more performant way that is recommended): `dataset.table.select().batches()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8d3ca-606a-41ae-b257-ae2a75af8af5",
   "metadata": {},
   "source": [
    "### Single batch (for smaller datasets)\n",
    "A useful way to get the data directly into a single Pandas DataFrame if you are dealing with small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffeb5a9-41de-4dd9-b516-52cb9e31fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset: 2241 marine observations\n"
     ]
    }
   ],
   "source": [
    "# Get all marine observations as single pandas DataFrame\n",
    "result_dataframe = dataset.table.select().all().dataframe()\n",
    "print(f\"Complete dataset: {len(result_dataframe)} marine observations\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a02a3c-09b9-41f9-8214-580c1bbf846d",
   "metadata": {},
   "source": [
    "You can protect from memory overflow by setting:\n",
    "* max_row (the maximum of rows to be returned in the Python DataFrame\n",
    "* max_time (time out threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb5c229-ec18-4327-bfc2-f7a75149e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset: 2241 marine observations\n"
     ]
    }
   ],
   "source": [
    "# Get all marine observations as single pandas DataFrame\n",
    "result_dataframe = dataset.table.select().all(max_rows=10_000_000_000, max_time=30.0).dataframe()\n",
    "print(f\"Complete dataset: {len(result_dataframe)} marine observations\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e8d32-8b31-443a-ad04-ba6c7cd38194",
   "metadata": {},
   "source": [
    "### Streaming batches query\n",
    "Ocean datasets are usually quite large and often it is better to get the data streaming.\n",
    "\n",
    "You have two different ways of streaming the: Pandas DataFrames (dataframes), and PyArrow RecordBatch (batches). Working with PyArrow has a performance advantage (memory efficient) and recommended if you are familiar with PyArrow (https://arrow.apache.org/docs/python/index.html), but Pandas is often what most users are more familiar with. However, it easy to convert from PyArrow RecordBatch to Pandas DataFrame.\n",
    "\n",
    "The streaming is design to allow you stop the streaming at any point when you are done with the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d8f14f-7cf6-494e-918b-05b0c830bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing DataFrame batch: 2241 observations\n",
      "Depth statistics: count    2207.000000\n",
      "mean     1672.336792\n",
      "std       997.570882\n",
      "min         9.500000\n",
      "25%       858.000000\n",
      "50%      1738.000000\n",
      "75%      2322.500000\n",
      "max      4836.000000\n",
      "Name: minimumDepthInMeters, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Iterate by Pandas DataFrames - convenient for analysis\n",
    "for dataframe_batch in dataset.table.select().dataframes():\n",
    "    print(f\"Analyzing DataFrame batch: {len(dataframe_batch)} observations\")\n",
    "    # Marine biology analysis on chunk\n",
    "    depth_stats = dataframe_batch['minimumDepthInMeters'].describe()\n",
    "    print(f\"Depth statistics: {depth_stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a112f1eb-0d2d-4dca-b69f-acae31be9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch with 2241 observations\n",
      "Found 36 unique species in this batch\n"
     ]
    }
   ],
   "source": [
    "# Iterate by batches (PyArrow RecordBatch) - memory efficient for large datasets\n",
    "for batch in dataset.table.select().batches():\n",
    "    print(f\"Processing batch with {batch.num_rows} observations\")\n",
    "    # Convert to Pandas\n",
    "    df_batch = batch.to_pandas()\n",
    "    # Process marine species in this batch\n",
    "    unique_species = df_batch['scientificName'].nunique()\n",
    "    print(f\"Found {unique_species} unique species in this batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08d20d-4840-4039-b237-e9b9cdb76360",
   "metadata": {},
   "source": [
    "### Basic select() Operations\n",
    "\n",
    "Within the select() method you can pass operators to narrow down:\n",
    "* Comparison: `AND`, `OR`, `NOT` \n",
    "* Logical: `>`, `<`, `>=`, `<=`, `==`, `!=` as well as `IS NULL`,`IS NOT NULL`\n",
    "* Geospatial: `within`, `intersects`, `contains`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4a8b9-4466-4b97-8f1d-bb918c0a3656",
   "metadata": {},
   "source": [
    "Examples are shown with single batch method, but works in the same way for streaming methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c09435e-149c-49e3-95a7-1d439f8a67d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 143\n"
     ]
    }
   ],
   "source": [
    "# Select specific\n",
    "dataframe = dataset.table.select(\"scientificName == 'Balaenoptera'\").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9968a263-a10d-4f07-8245-ff3d97271f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 143\n"
     ]
    }
   ],
   "source": [
    "# Explicit parameter\n",
    "dataframe = dataset.table.select(filter=\"scientificName == 'Balaenoptera'\").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff3c1ce-c06b-49c8-ae04-8d261c90e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2170\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns which is more efficient than selecting all columns and filtering in Python\n",
    "dataframe = dataset.table.select(\n",
    "    \"minimumDepthInMeters > 100\", \n",
    "    cols=[\"scientificName\", \"lifeStage\", \"minimumDepthInMeters\", \"eventDate\"]\n",
    ").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87732bed-448c-41bf-8ee6-01cc0db72825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 141\n"
     ]
    }
   ],
   "source": [
    "# Select with multiple variables\n",
    "dataframe = dataset.select(\n",
    "    \"scientificName == 'Balaenoptera' AND minimumDepthInMeters > 100\"\n",
    ").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644a7d54-d675-48bf-a68f-f1d8333ff46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 143\n"
     ]
    }
   ],
   "source": [
    "# Select with named bind variables for safe, efficient queries:\n",
    "dataframe = dataset.table.select(\n",
    "    \"scientificName == $species\",\n",
    "    vars={\n",
    "        \"species\": \"Balaenoptera\"\n",
    "    }\n",
    ").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcaa167c-c969-4793-9765-bd7d04602706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1395\n"
     ]
    }
   ],
   "source": [
    "# How to work with geo\n",
    "dataframe = dataset.table.select(\n",
    "    'footprintWKT within $area', \n",
    "    vars={\"area\": \"POLYGON((-37 -12, -45 -26, -40 -28, -33 -13, -37 -12))\"},\n",
    ").all().dataframe()\n",
    "print(f\"Number of rows: {dataframe.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd466a5-5457-40b5-834d-ab33850a7266",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "Some description on aggregations\n",
    "- max\n",
    "- min\n",
    "- sum\n",
    "- count\n",
    "- mean (average)\n",
    "\n",
    "Geo aggregations\n",
    "- h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b78f23f8-5f2e-4adf-a7a1-996e2cd99199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             *  minimumDepthInMeters\n",
      "                                    \n",
      "None       498           2108.367470\n",
      "adult     1606           1544.799809\n",
      "juvenile   137           1550.766423\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by a column\n",
    "dataframe = dataset.table.aggregate(\n",
    "    group_by=\"lifeStage\",\n",
    "    aggr={\"minimumDepthInMeters\": \"mean\"}\n",
    ")\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a155cdd7-d5da-40c2-af68-25dba445b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              *  minimumDepthInMeters\n",
      "                                                     \n",
      "Balaenoptera                143           1796.202797\n",
      "Balaenoptera acutorostrata   51           1925.647059\n",
      "Balaenoptera bonaerensis      4           2616.000000\n",
      "Balaenoptera brydei           1           1456.000000\n",
      "Balaenoptera edeni            4           2027.000000\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by a column combined with a query\n",
    "dataframe = dataset.table.aggregate(\n",
    "    group_by=\"scientificName\",\n",
    "    filter=\"scientificName IS NOT NULL AND minimumDepthInMeters IS NOT NULL\",\n",
    "    aggr={\n",
    "        \"minimumDepthInMeters\": \"mean\"\n",
    "    }\n",
    ")\n",
    "print(dataframe.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57697da4-725a-4503-9c91-7df14e78bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          *  minimumDepthInMeters\n",
      "                                 \n",
      "TOTAL  2241                4836.0\n"
     ]
    }
   ],
   "source": [
    "# Aggregate without grouping\n",
    "dataframe = dataset.table.aggregate(\n",
    "    group_by='\"TOTAL\"',  # Special value\n",
    "    aggr={ \n",
    "        \"minimumDepthInMeters\": \"max\"\n",
    "    }\n",
    ")\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cef36eb-8179-4d6e-8798-56d95979857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 *  minimumDepthInMeters\n",
      "                                        \n",
      "85801047fffffff  1                   9.5\n",
      "85801203fffffff  3                   NaN\n",
      "85801207fffffff  2                   NaN\n",
      "8580120bfffffff  1                   NaN\n",
      "8580120ffffffff  1                   NaN\n",
      "...             ..                   ...\n",
      "85c51c63fffffff  1                 458.0\n",
      "85c51d2bfffffff  1                4000.0\n",
      "85c51d47fffffff  5                4000.0\n",
      "85c51d57fffffff  1                4000.0\n",
      "85c51d73fffffff  4                4000.0\n",
      "\n",
      "[582 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate by h3 hexagons\n",
    "dataframe = dataset.table.aggregate(\n",
    "    group_by=\"h3(footprintWKT, 5)\", # Arguments: Column containing the geometry, and resolution between 0 and 15 https://h3geo.org/docs/core-library/restable/\n",
    "    filter=\"footprintWKT IS NOT NULL\",\n",
    "    aggr={\n",
    "        \"minimumDepthInMeters\": \"mean\"\n",
    "    }\n",
    ")\n",
    "print(dataframe.iloc[0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5f14e-4206-45f2-be80-ba1f09add415",
   "metadata": {},
   "source": [
    "### Performance tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6842037-8819-4778-b341-163bcbeab8a7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Use column selection: Only select columns you need.\n",
    "2. Use bind variables: More efficient than string concatenation (safer as well).\n",
    "3. Filter early: Apply filters in the query rather than in Python.\n",
    "4. Consider aggregation: Use aggregate() instead of selecting all data and aggregating in Python.\n",
    "5. Use Streaming: Handle large datasets by streaming and iterate them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa13c9-eec9-4cd9-9cdb-617ca9cf020d",
   "metadata": {},
   "source": [
    "### Error handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b506e103-ce51-442a-bfd5-0413176a576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query error: {\"error\": \"Can't parse:\\ninvalid_column =! 5\\n                ^\\n\\nNo terminal matches '!' in the current parser context, at line 1 col 17\\n\\ninvalid_column =! 5\\n                ^\\nExpected one of: \\n\\t* NAME\\n\\t* LPAR\\n\\t* /(True|False|None|null|true|false)/\\n\\t* ESCAPED_STRING\\n\\t* SIGNED_NUMBER\\n\\t* DOLLAR\\n\\t* TILDE\\n\\t* /'[^']*'/\\n\\t* QMARK\\n\\nPrevious tokens: Token('__ANON_1', '=')\\n\", \"request-id\": \"d8d782dcaab2\"}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "try:\n",
    "    result = dataset.table.select(\"invalid_column =! 5\").all().dataframe()\n",
    "except ValueError as e:\n",
    "    print(f\"Query error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
